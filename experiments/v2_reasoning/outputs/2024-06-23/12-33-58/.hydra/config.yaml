n_prompts: 5
n_shots: 2
dataset_split: train
cache_dir: /scr/jphilipp/tstar/datasets/gsm
save_file: data/base_responses/base_responses.json
model_config:
  model: meta-llama/Meta-Llama-3-8B-Instruct
  download_dir: /scr/jphilipp/stargate/pretrained_models/Meta-Llama-3-8B-Instruct
  dtype: auto
  quantization: null
  tensor_parallel_size: 1
generation_config:
  max_new_tokens: 2048
  num_return_sequences: $n_shots
  best_of: $n_shots
  temperature: 1.0
