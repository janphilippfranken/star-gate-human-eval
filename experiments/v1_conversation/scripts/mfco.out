[2024-07-04 09:34:27,682][root][INFO] - Computing MI from Convo.
Saving to: data/mutual_information/debug_mi_2.json
Convo file: data/conversations/hai_start_0_end_200_n_user_2_seed_0_12.json
INFO 07-04 09:34:27 llm_engine.py:79] Initializing an LLM engine with config: model='meta-llama/Meta-Llama-3-8B-Instruct', tokenizer='meta-llama/Meta-Llama-3-8B-Instruct', tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=8192, download_dir='/scr/jphilipp/stargate/pretrained_models/Meta-Llama-3-8B-Instruct', load_format=auto, tensor_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, seed=0)
INFO 07-04 09:34:30 weight_utils.py:163] Using model weights format ['*.safetensors']
INFO 07-04 09:34:33 llm_engine.py:337] # GPU blocks: 27885, # CPU blocks: 2048
INFO 07-04 09:34:34 model_runner.py:666] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 07-04 09:34:34 model_runner.py:670] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 07-04 09:34:37 model_runner.py:738] Graph capturing finished in 3 secs.
NAME
    mutual_information_from_conversation.py

SYNOPSIS
    mutual_information_from_conversation.py GROUP | COMMAND | VALUE

GROUPS
    GROUP is one of the following:

     json
       JSON (JavaScript Object Notation) <http://json.org> is a subset of JavaScript syntax (ECMA-262 3rd edition) used as a lightweight data interchange format.

     fire
       The Python Fire module.

     hydra

     tqdm

     logging
       Logging package for Python. Based on PEP 282 and comments thereto in comp.lang.python.

     torch
       The torch package contains data structures for multi-dimensional tensors and defines mathematical operations over these tensors. Additionally, it provides many utilities for efficient serialization of Tensors and arbitrary types, and other useful utilities.

     np
       NumPy =====

     Dict
       A generic version of dict.

     Sequence
       A generic version of collections.abc.Sequence.

     List
       A generic version of list.

     copy
       Generic (shallow and deep) copying operations.

     transformers

     ROLEPLAY_PROMPTS

     users

     f
       Character and line based layer over a BufferedIOBase object, buffer.

COMMANDS
    COMMAND is one of the following:

     DictConfig
       Container tagging interface

     AutoTokenizer
       This is a generic tokenizer class that will be instantiated as one of the tokenizer classes of the library when created with the [`AutoTokenizer.from_pretrained`] class method.

     VLLMInferenceModel
       Simple vLLM Inference Wrapper for text generation and logprobs.

     dataclass
       Returns the same class as was passed in, with dunder methods added based on the fields defined in the class.

     Dataset
       A Dataset backed by an Arrow table.

     get_formatted_responses
       Formats prompts and returns formatted model responses.

     mutual_information
       Computes mutual information.

     DataCollatorForSupervisedDataset
       Data collator for SFT which masks user from the loss.

     preprocess
       Preprocess the data by tokenizing.

     main

VALUES
    VALUE is one of the following:

     IGNORE_INDEX

     ORACLE_PROMPT

     RESPONSE_PROMPT

     PROMPT_LOGPROBS

     PROMPT_LOGPROBS_2

     QUESTION_PROMPT

     ROLEPLAY_PROMPT

     ROLEPLAY_PROMPT_2

     FINAL_RESPONSE_PROMPT

     USER_PREDICTION_PROMPT

     PERSONA

     USER_0

     USER_1

     USER_2

     USER_3

     USER_4

     USER_5

     USER_6

     USER_7

     USER_8

     USER_9

     USER_10

     USER_11

     USER_12

     USER_13

     USER_14

     USER_15

     USER_16

     USER_17

     USER_18

     USER_19

     USER_20

     USER_21

     USER_22

     USER_23

     USER_24
